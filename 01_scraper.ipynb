{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import re\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Define the relative path to the CSV file\n",
    "csv_path = os.path.join(cwd, 'Shitstorms.csv')\n",
    "\n",
    "# Read the CSV file using pandas\n",
    "df = pd.read_csv(csv_path, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ShitstormID</th>\n",
       "      <th>Profilname</th>\n",
       "      <th>sp1</th>\n",
       "      <th>ep1</th>\n",
       "      <th>sp2</th>\n",
       "      <th>ep2</th>\n",
       "      <th>sp3</th>\n",
       "      <th>ep3</th>\n",
       "      <th>sp4</th>\n",
       "      <th>ep4</th>\n",
       "      <th>sp5</th>\n",
       "      <th>ep5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>barilla</td>\n",
       "      <td>2013-09-24</td>\n",
       "      <td>2013-09-25</td>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>2013-09-27</td>\n",
       "      <td>2013-09-28</td>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2013-10-03</td>\n",
       "      <td>2013-10-04</td>\n",
       "      <td>2013-10-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>otto</td>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>2021-10-30</td>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>2021-11-05</td>\n",
       "      <td>2021-11-10</td>\n",
       "      <td>2021-11-11</td>\n",
       "      <td>2021-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>EMMA_Magazin</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>2016-01-09</td>\n",
       "      <td>2016-01-10</td>\n",
       "      <td>2016-01-11</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>2016-01-21</td>\n",
       "      <td>2016-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gillette</td>\n",
       "      <td>2019-01-15</td>\n",
       "      <td>2019-01-16</td>\n",
       "      <td>2019-01-17</td>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>2019-01-19</td>\n",
       "      <td>2019-01-21</td>\n",
       "      <td>2019-01-22</td>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>2019-01-26</td>\n",
       "      <td>2019-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Kaufland</td>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>2020-10-10</td>\n",
       "      <td>2020-10-11</td>\n",
       "      <td>2020-10-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ShitstormID    Profilname         sp1         ep1         sp2         ep2  \\\n",
       "0            1       barilla  2013-09-24  2013-09-25  2013-09-26  2013-09-26   \n",
       "1            2          otto  2021-10-29  2021-10-30  2021-10-01  2021-11-02   \n",
       "2            3  EMMA_Magazin  2016-01-07  2016-01-08  2016-01-09  2016-01-10   \n",
       "3            4      Gillette  2019-01-15  2019-01-16  2019-01-17  2019-01-18   \n",
       "4            5      Kaufland  2020-10-07  2020-10-07  2020-10-07  2020-10-07   \n",
       "\n",
       "          sp3         ep3         sp4         ep4         sp5         ep5  \n",
       "0  2013-09-27  2013-09-28  2013-09-29  2013-10-03  2013-10-04  2013-10-10  \n",
       "1  2021-11-03  2021-11-04  2021-11-05  2021-11-10  2021-11-11  2021-11-30  \n",
       "2  2016-01-11  2016-01-13  2016-01-14  2016-01-20  2016-01-21  2016-02-10  \n",
       "3  2019-01-19  2019-01-21  2019-01-22  2019-01-25  2019-01-26  2019-02-10  \n",
       "4  2020-10-07  2020-10-08  2020-10-09  2020-10-10  2020-10-11  2020-10-16  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    number       start         end\n",
      "0        1  2013-09-24  2013-09-25\n",
      "1        2  2013-09-26  2013-09-26\n",
      "2        3  2013-09-27  2013-09-28\n",
      "3        4  2013-09-29  2013-10-03\n",
      "4        5  2013-10-04  2013-10-10\n",
      "5        1  2021-10-29  2021-10-30\n",
      "6        2  2021-10-01  2021-11-02\n",
      "7        3  2021-11-03  2021-11-04\n",
      "8        4  2021-11-05  2021-11-10\n",
      "9        5  2021-11-11  2021-11-30\n",
      "10       1  2016-01-07  2016-01-08\n",
      "11       2  2016-01-09  2016-01-10\n",
      "12       3  2016-01-11  2016-01-13\n",
      "13       4  2016-01-14  2016-01-20\n",
      "14       5  2016-01-21  2016-02-10\n",
      "15       1  2019-01-15  2019-01-16\n",
      "16       2  2019-01-17  2019-01-18\n",
      "17       3  2019-01-19  2019-01-21\n",
      "18       4  2019-01-22  2019-01-25\n",
      "19       5  2019-01-26  2019-02-10\n",
      "20       1  2020-10-07  2020-10-07\n",
      "21       2  2020-10-07  2020-10-07\n",
      "22       3  2020-10-07  2020-10-08\n",
      "23       4  2020-10-09  2020-10-10\n",
      "24       5  2020-10-11  2020-10-16\n",
      "25       1  2020-01-28  2020-01-28\n",
      "26       2  2020-01-28  2020-01-28\n",
      "27       3  2020-01-28  2020-01-28\n",
      "28       4  2020-01-29  2020-02-01\n",
      "29       5  2020-02-02  2020-02-06\n",
      "30       1  2023-01-17  2023-01-17\n",
      "31       2  2023-01-17  2023-01-17\n",
      "32       3  2023-01-17  2023-01-17\n",
      "33       4  2023-01-17  2023-01-18\n",
      "34       5  2023-01-18  2023-01-18\n",
      "35       1  2017-07-04  2017-07-04\n",
      "36       2  2017-07-04  2017-07-04\n",
      "37       3  2017-07-04  2017-07-05\n",
      "38       4  2017-07-06  2017-07-11\n",
      "39       5  2017-07-12  2017-07-18\n",
      "40       1  2019-08-01  2019-08-01\n",
      "41       2  2019-08-01  2019-08-01\n",
      "42       3  2019-08-01  2019-08-02\n",
      "43       4  2019-08-03  2019-08-05\n",
      "44       5  2019-08-05  2019-08-05\n",
      "45       1  2019-12-20  2019-12-20\n",
      "46       2  2019-12-20  2019-12-21\n",
      "47       3  2019-12-22  2019-12-23\n",
      "48       4  2019-12-24  2019-12-28\n",
      "49       5  2019-12-29  2020-01-02\n"
     ]
    }
   ],
   "source": [
    "# create a list to store the new data\n",
    "new_data = []\n",
    "\n",
    "# iterate over the rows of the original dataframe\n",
    "for index, row in df.iterrows():\n",
    "    for i in range(1, 6):\n",
    "        # extract the start and end dates from the original dataframe\n",
    "        start = row[f'sp{i}']\n",
    "        end = row[f'ep{i}']\n",
    "        # create a new row with the desired columns\n",
    "        new_row = {\n",
    "            'number': i,\n",
    "            'start': start,\n",
    "            'end': end\n",
    "        }\n",
    "        # add the new row to the list\n",
    "        new_data.append(new_row)\n",
    "\n",
    "# create the new dataframe\n",
    "new_df = pd.DataFrame(new_data)\n",
    "\n",
    "# print the new dataframe\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(to:barilla) until:2013-09-25 since:2013-09-24\n",
      "(to:barilla) until:2013-09-26 since:2013-09-25\n",
      "(to:barilla) until:2013-09-26 since:2013-09-26\n",
      "(to:barilla) until:2013-09-27 since:2013-09-26\n",
      "(to:barilla) until:2013-09-28 since:2013-09-27\n",
      "(to:barilla) until:2013-09-29 since:2013-09-28\n",
      "(to:barilla) until:2013-10-03 since:2013-09-29\n",
      "(to:barilla) until:2013-10-04 since:2013-10-03\n",
      "(to:barilla) until:2013-10-10 since:2013-10-04\n",
      "(to:otto) until:2021-10-30 since:2021-10-29\n",
      "(to:otto) until:2021-10-01 since:2021-10-30\n",
      "(to:otto) until:2021-11-02 since:2021-10-01\n",
      "(to:otto) until:2021-11-03 since:2021-11-02\n",
      "(to:otto) until:2021-11-04 since:2021-11-03\n",
      "(to:otto) until:2021-11-05 since:2021-11-04\n",
      "(to:otto) until:2021-11-10 since:2021-11-05\n",
      "(to:otto) until:2021-11-11 since:2021-11-10\n",
      "(to:otto) until:2021-11-30 since:2021-11-11\n",
      "(to:EMMA_Magazin) until:2016-01-08 since:2016-01-07\n",
      "(to:EMMA_Magazin) until:2016-01-09 since:2016-01-08\n",
      "(to:EMMA_Magazin) until:2016-01-10 since:2016-01-09\n",
      "(to:EMMA_Magazin) until:2016-01-11 since:2016-01-10\n",
      "(to:EMMA_Magazin) until:2016-01-13 since:2016-01-11\n",
      "(to:EMMA_Magazin) until:2016-01-14 since:2016-01-13\n",
      "(to:EMMA_Magazin) until:2016-01-20 since:2016-01-14\n",
      "(to:EMMA_Magazin) until:2016-01-21 since:2016-01-20\n",
      "(to:EMMA_Magazin) until:2016-02-10 since:2016-01-21\n",
      "(to:Gillette) until:2019-01-16 since:2019-01-15\n",
      "(to:Gillette) until:2019-01-17 since:2019-01-16\n",
      "(to:Gillette) until:2019-01-18 since:2019-01-17\n",
      "(to:Gillette) until:2019-01-19 since:2019-01-18\n",
      "(to:Gillette) until:2019-01-21 since:2019-01-19\n",
      "(to:Gillette) until:2019-01-22 since:2019-01-21\n",
      "(to:Gillette) until:2019-01-25 since:2019-01-22\n",
      "(to:Gillette) until:2019-01-26 since:2019-01-25\n",
      "(to:Gillette) until:2019-02-10 since:2019-01-26\n",
      "(to:Kaufland) until:2020-10-07 since:2020-10-07\n",
      "(to:Kaufland) until:2020-10-07 since:2020-10-07\n",
      "(to:Kaufland) until:2020-10-07 since:2020-10-07\n",
      "(to:Kaufland) until:2020-10-07 since:2020-10-07\n",
      "(to:Kaufland) until:2020-10-08 since:2020-10-07\n",
      "(to:Kaufland) until:2020-10-09 since:2020-10-08\n",
      "(to:Kaufland) until:2020-10-10 since:2020-10-09\n",
      "(to:Kaufland) until:2020-10-11 since:2020-10-10\n",
      "(to:Kaufland) until:2020-10-16 since:2020-10-11\n",
      "(to:Blizzard_Ent) until:2020-01-28 since:2020-01-28\n",
      "(to:Blizzard_Ent) until:2020-01-28 since:2020-01-28\n",
      "(to:Blizzard_Ent) until:2020-01-28 since:2020-01-28\n",
      "(to:Blizzard_Ent) until:2020-01-28 since:2020-01-28\n",
      "(to:Blizzard_Ent) until:2020-01-28 since:2020-01-28\n",
      "(to:Blizzard_Ent) until:2020-01-29 since:2020-01-28\n",
      "(to:Blizzard_Ent) until:2020-02-01 since:2020-01-29\n",
      "(to:Blizzard_Ent) until:2020-02-02 since:2020-02-01\n",
      "(to:Blizzard_Ent) until:2020-02-06 since:2020-02-02\n",
      "(to:YvonneMagwas) until:2023-01-17 since:2023-01-17\n",
      "(to:YvonneMagwas) until:2023-01-17 since:2023-01-17\n",
      "(to:YvonneMagwas) until:2023-01-17 since:2023-01-17\n",
      "(to:YvonneMagwas) until:2023-01-17 since:2023-01-17\n",
      "(to:YvonneMagwas) until:2023-01-17 since:2023-01-17\n",
      "(to:YvonneMagwas) until:2023-01-17 since:2023-01-17\n",
      "(to:YvonneMagwas) until:2023-01-18 since:2023-01-17\n",
      "(to:YvonneMagwas) until:2023-01-18 since:2023-01-18\n",
      "(to:YvonneMagwas) until:2023-01-18 since:2023-01-18\n",
      "(to:petertauber) until:2017-07-04 since:2017-07-04\n",
      "(to:petertauber) until:2017-07-04 since:2017-07-04\n",
      "(to:petertauber) until:2017-07-04 since:2017-07-04\n",
      "(to:petertauber) until:2017-07-04 since:2017-07-04\n",
      "(to:petertauber) until:2017-07-05 since:2017-07-04\n",
      "(to:petertauber) until:2017-07-06 since:2017-07-05\n",
      "(to:petertauber) until:2017-07-11 since:2017-07-06\n",
      "(to:petertauber) until:2017-07-12 since:2017-07-11\n",
      "(to:petertauber) until:2017-07-18 since:2017-07-12\n",
      "(to:MercedesBenz) until:2019-08-01 since:2019-08-01\n",
      "(to:MercedesBenz) until:2019-08-01 since:2019-08-01\n",
      "(to:MercedesBenz) until:2019-08-01 since:2019-08-01\n",
      "(to:MercedesBenz) until:2019-08-01 since:2019-08-01\n",
      "(to:MercedesBenz) until:2019-08-02 since:2019-08-01\n",
      "(to:MercedesBenz) until:2019-08-03 since:2019-08-02\n",
      "(to:MercedesBenz) until:2019-08-05 since:2019-08-03\n",
      "(to:MercedesBenz) until:2019-08-05 since:2019-08-05\n",
      "(to:MercedesBenz) until:2019-08-05 since:2019-08-05\n",
      "(to:jk_rowling) until:2019-12-20 since:2019-12-20\n",
      "(to:jk_rowling) until:2019-12-20 since:2019-12-20\n",
      "(to:jk_rowling) until:2019-12-21 since:2019-12-20\n",
      "(to:jk_rowling) until:2019-12-22 since:2019-12-21\n",
      "(to:jk_rowling) until:2019-12-23 since:2019-12-22\n",
      "(to:jk_rowling) until:2019-12-24 since:2019-12-23\n",
      "(to:jk_rowling) until:2019-12-28 since:2019-12-24\n",
      "(to:jk_rowling) until:2019-12-29 since:2019-12-28\n",
      "(to:jk_rowling) until:2020-01-02 since:2019-12-29\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    for j, col in enumerate(row[1:], start=2):\n",
    "        if j < len(row) - 1:\n",
    "            query = \"(to:{}) until:{} since:{}\".format(row['Profilname'],row[j+1], row[j])\n",
    "            \n",
    "            print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(to:barilla) until:2013-09-24 since:2013-09-24\n",
      "(to:barilla) until:2013-09-25 since:2013-09-25\n",
      "(to:barilla) until:2013-09-27 since:2013-09-26\n",
      "(to:barilla) until:2013-10-01 since:2013-09-28\n",
      "(to:barilla) until:2013-10-15 since:2013-10-02\n",
      "(to:kitkat) until:2010-03-17 since:2010-03-17\n",
      "(to:kitkat) until:2010-03-18 since:2010-03-18\n",
      "(to:kitkat) until:2010-03-19 since:2010-03-19\n",
      "(to:kitkat) until:2010-03-23 since:2010-03-20\n",
      "(to:kitkat) until:2010-04-05 since:2010-03-24\n",
      "(to:otto) until:2021-10-28 since:2021-10-28\n",
      "(to:otto) until:2021-10-29 since:2021-10-29\n",
      "(to:otto) until:2021-10-30 since:2021-10-30\n",
      "(to:otto) until:2021-11-04 since:2021-10-31\n",
      "(to:otto) until:2021-11-30 since:2021-11-05\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame(columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content'])\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    new_data = []\n",
    "    for i in range(1, 6):\n",
    "        # extract the start and end dates from the original dataframe\n",
    "        start = row[f'sp{i}']\n",
    "        end = row[f'ep{i}']\n",
    "        # create a new row with the desired columns\n",
    "        new_row = {\n",
    "            'number': i,\n",
    "            'start': start,\n",
    "            'end': end\n",
    "        }\n",
    "        # add the new row to the list\n",
    "        new_data.append(new_row)\n",
    "\n",
    "    # create the new dataframe\n",
    "    new_df = pd.DataFrame(new_data)\n",
    "    \n",
    "    for j, col in new_df.iterrows():\n",
    "        query = \"(to:{}) until:{} since:{}\".format(row['Profilname'], col['end'], col['start'])\n",
    "        limit = 2\n",
    "        tweets = []\n",
    "\n",
    "        print (query)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Unavailable user in card on tweet 1086720561512734720\n",
      "Unavailable user in card on tweet 1086720561512734720\n",
      "User 1596469960708165632 not found in user refs in card on tweet 1086720561512734720\n",
      "User 1596469960708165632 not found in user refs in card on tweet 1086720561512734720\n",
      "Unavailable user in card on tweet 1086720561512734720\n",
      "Unavailable user in card on tweet 1086720561512734720\n",
      "User 1596469960708165632 not found in user refs in card on tweet 1086720561512734720\n",
      "User 1596469960708165632 not found in user refs in card on tweet 1086720561512734720\n",
      "Unavailable user in card on tweet 1086720561512734720\n",
      "Unavailable user in card on tweet 1086720561512734720\n",
      "User 1596469960708165632 not found in user refs in card on tweet 1086720561512734720\n",
      "User 1596469960708165632 not found in user refs in card on tweet 1086720561512734720\n",
      "Unavailable user in card on tweet 1086720561512734720\n",
      "Unavailable user in card on tweet 1086720561512734720\n",
      "User 1596469960708165632 not found in user refs in card on tweet 1086720561512734720\n",
      "User 1596469960708165632 not found in user refs in card on tweet 1086720561512734720\n",
      "Unavailable user in card on tweet 1086720561512734720\n",
      "Unavailable user in card on tweet 1086720561512734720\n",
      "User 1596469960708165632 not found in user refs in card on tweet 1086720561512734720\n",
      "User 1596469960708165632 not found in user refs in card on tweet 1086720561512734720\n",
      "Unavailable user in card on tweet 1086720561512734720\n",
      "Unavailable user in card on tweet 1086720561512734720\n",
      "User 1596469960708165632 not found in user refs in card on tweet 1086720561512734720\n",
      "User 1596469960708165632 not found in user refs in card on tweet 1086720561512734720\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Empty user ref object in card on tweet 1090032233182834688\n",
      "User 899733078641225728 not found in user refs in card on tweet 1090032233182834688\n",
      "Unavailable user in card on tweet 1089577883624828928\n",
      "Unavailable user in card on tweet 1089577883624828928\n",
      "User 15843059 not found in user refs in card on tweet 1089577883624828928\n",
      "User 15843059 not found in user refs in card on tweet 1089577883624828928\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
      "Stopping after 20 empty pages\n",
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_12504\\2455835138.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame(columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content'])\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    new_data = []\n",
    "    for i in range(1, 6):\n",
    "        # extract the start and end dates from the original dataframe\n",
    "        start = row[f'sp{i}']\n",
    "        end = row[f'ep{i}']\n",
    "        # create a new row with the desired columns\n",
    "        new_row = {\n",
    "            'number': i,\n",
    "            'start': start,\n",
    "            'end': end\n",
    "        }\n",
    "        # add the new row to the list\n",
    "        new_data.append(new_row)\n",
    "\n",
    "    # create the new dataframe\n",
    "    new_df = pd.DataFrame(new_data)\n",
    "    \n",
    "    for j, col in new_df.iterrows():\n",
    "        query = \"(to:{}) until:{} since:{}\".format(row['Profilname'], col['end'], col['start'])\n",
    "        limit = 5000\n",
    "        tweets = []\n",
    "\n",
    "        for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "            \n",
    "            if len(tweets)==limit:\n",
    "                break\n",
    "            else:\n",
    "                \n",
    "                tweets.append([int(index), int(j), tweet.retweetCount, tweet.likeCount, tweet.replyCount, re.sub(r'@[^\\s]+', '', tweet.rawContent, count=1)])\n",
    "\n",
    "        df1 = df1.append(pd.DataFrame(tweets, columns=['ssid', 'phase', 'retweetCount','likeCount','replyCount','content']))\n",
    "\n",
    "df1.to_csv('C:/Users/fhb181029/Documents/FH/S9/MasterArbeit/Prototyp/Datascrape.csv', sep=';',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('C:/Users/fhb181029/Documents/FH/S9/MasterArbeit/Prototyp/Datascrape.csv', sep=';',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         inReply  \\\n",
      "0  https://twitter.com/ArminWolf   \n",
      "1  https://twitter.com/ArminWolf   \n",
      "2  https://twitter.com/ArminWolf   \n",
      "3  https://twitter.com/ArminWolf   \n",
      "4  https://twitter.com/ArminWolf   \n",
      "5  https://twitter.com/ArminWolf   \n",
      "6  https://twitter.com/ArminWolf   \n",
      "7  https://twitter.com/ArminWolf   \n",
      "8  https://twitter.com/ArminWolf   \n",
      "9  https://twitter.com/ArminWolf   \n",
      "\n",
      "                                             content  \\\n",
      "0  @ArminWolf Mißratener Aprilscherz, oder hat er...   \n",
      "1  @ArminWolf Fakt ist, dass an den Stammtischen ...   \n",
      "2  @ArminWolf Sehe ich ganz genauso.\\nAlternative...   \n",
      "3  @ArminWolf Danke, Herr Wolf für ihre objektive...   \n",
      "4               @ArminWolf Safe, oder? @SWagenknecht   \n",
      "5  @ArminWolf Ja ab und zu schon. Zwar nicht imme...   \n",
      "6  @ArminWolf Wenn die“ Banker\" zuerst etwa 8 Jah...   \n",
      "7  @ArminWolf Der ach-so-tolle-Journalist sollte ...   \n",
      "8  @ArminWolf Immer dran denken: wer andere zwing...   \n",
      "9  @ArminWolf Einen schurkenstaat wir die Ukraine...   \n",
      "\n",
      "                                                 url  \n",
      "0  https://twitter.com/hummler/status/16423151054...  \n",
      "1  https://twitter.com/nomessagecontro/status/164...  \n",
      "2  https://twitter.com/nix_wird/status/1642311477...  \n",
      "3  https://twitter.com/77rubin/status/16423067885...  \n",
      "4  https://twitter.com/GregorsPolitik/status/1642...  \n",
      "5  https://twitter.com/ZapfelChristian/status/164...  \n",
      "6  https://twitter.com/IchmachdA/status/164229355...  \n",
      "7  https://twitter.com/zerotonin77/status/1642292...  \n",
      "8  https://twitter.com/Elafant70/status/164228986...  \n",
      "9  https://twitter.com/Elafant70/status/164228973...  \n"
     ]
    }
   ],
   "source": [
    "#use this to get by search query\n",
    "query=\"(to:arminwolf) until:2023-04-02 since:2023-04-01\"\n",
    "\n",
    "tweets = []\n",
    "limit = 10\n",
    "\n",
    "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "    if len(tweets)==limit:\n",
    "        break\n",
    "    else:\n",
    "        tweets.append([tweet.inReplyToUser,tweet.rawContent, tweet.url])\n",
    "\n",
    "df1 = pd.DataFrame(tweets, columns=['inReply','content','url'])\n",
    "\n",
    "print (df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://twitter.com/alfabet1999 @alfabet1999 Ja. https://twitter.com/ArminWolf/status/1647934211498688515\n",
      "https://twitter.com/yhigh @yhigh @FHabersberger Wenn Sie mir ein Finanzprodukt zeigen, dass mit einer Kapitalgarantie (!) seit 2003 im Schnitt 6% p.a. gemacht hat, nehme ich alles zurück. https://twitter.com/ArminWolf/status/1647933896665833477\n",
      "https://twitter.com/Sprenger3Kl @Sprenger3Kl @elflanell @FranzZapflhuber Sie meinen, dass ich vor 40 Jahren Mitglied einer polit. Jugendorganisation war, aus der ich ausgetreten bin, als ich Journalist wurde, widerspricht „dezitiert“ meinem objektiven Journalismus? Ah ja. \n",
      "Mein Tipp: Don‘t drink and tweet! \n",
      "Salut! https://twitter.com/ArminWolf/status/1647933081053978625\n",
      "https://twitter.com/MichaelCsoklich @MichaelCsoklich Klar, aber auch beim erwarteten Zinssatz waren die 6% auf Dauer immer irreal. Es gab und gibt historisch keine Veranlagung mit Kapitalgarantie, die dauerhaft 6% jährlich bringt. https://twitter.com/ArminWolf/status/1647903193949454336\n",
      "https://twitter.com/FHabersberger @FHabersberger Ja, das war - bis auf die Niedrigzinspolitik der EZB - 2003 alles schon bekannt. Trotzdem wurden völlig irreale 6% pro Jahr vresprochen. https://twitter.com/ArminWolf/status/1647902849286778881\n",
      "https://twitter.com/attwenger3 @attwenger3 Da war ich schon einige Jahre aus Innsbruck weg. https://twitter.com/ArminWolf/status/1647902586605797377\n",
      "https://twitter.com/ArminWolf Wir haben beide wegen und gemeinsam bei Anton Pelinka studiert. Und Gerhard Mangott war der mit Abstand klügste und begabteste der - damals noch recht wenigen - Innsbrucker Politik-Studierenden. Wenige Menschen wissen so viel und können so fantastisch erklären. https://twitter.com/ArminWolf/status/1647895245575651329\n",
      "None Wusste bisher gar nicht, dass die ⁦@TTNachrichten⁩ so aufwändig produzierte Longreads haben, wie dieses schöne Porträt von Russland-Kenner und -Erklärer ⁦@gerhard_mangott⁩:  https://t.co/U81sP8k1xT https://twitter.com/ArminWolf/status/1647894575510372352\n",
      "https://twitter.com/ArminWolf Erklärt wird das jetzt übr. mit der Kapitalgarantie, die lukrativere, aber risikoreichere Veranlagungen unmöglich mache. \n",
      "Stimmt, das wusste man allerdings auch schon bei der Einführung von 20 Jahren. https://twitter.com/ArminWolf/status/1647892395118276610\n",
      "None Vor 20 Jahren wurde die „Abfertigung neu“ eingeführt. Ausgelegt wurde sie auf ein durchschnittliche (!) Verzinsung von 6% p.a.\n",
      "Jeder wusste, dass das illusorisch war, nur die damalige Regierung behauptete anderes. Nach 20 Jahren: Durchschnittlich 1,98%. https://t.co/zKYb0YosXO https://twitter.com/ArminWolf/status/1647891946176909313\n",
      "None Wenn man die ganze Geschichte rund um das Ibiza-Video mit deutschen Augen sieht, wird sie lnochmal bizarrer. \n",
      "Schönes Detail: Hier erfährt man, warum ⁦@janboehm⁩ in seiner Romy-Rede 2018 schon einen Monat vor dem Ibiza-Video wusste, was da kommt… https://t.co/7NoJ3dtPG2 https://twitter.com/ArminWolf/status/1647887316382281728\n"
     ]
    }
   ],
   "source": [
    "for i, tweet in enumerate(scraper.get_items()):\n",
    "    if i>10:\n",
    "        break\n",
    "    print (tweet.inReplyToUser,tweet.rawContent, tweet.url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://twitter.com/ArminWolf/status/1647894575510372352\n",
      "https://twitter.com/ArminWolf/status/1647895245575651329\n",
      "https://twitter.com/emmaKnigthly/status/1647899455960629249\n",
      "https://twitter.com/FunkhausZorra/status/1647900187963039744\n",
      "https://twitter.com/veronikaDapra/status/1647978166604931073\n",
      "https://twitter.com/veronikaDapra/status/1647978914638118914\n"
     ]
    }
   ],
   "source": [
    "# get replys \n",
    "\n",
    "mode = sntwitter.TwitterTweetScraperMode\n",
    "sncraper_reply = sntwitter.TwitterTweetScraper(tweetId=1647894575510372352, mode=mode.SCROLL)\n",
    "\n",
    "for i, tweet in enumerate(sncraper_reply.get_items()):\n",
    "    if i>5:\n",
    "        break\n",
    "    print (tweet.url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fhb181029\\AppData\\Local\\Temp\\ipykernel_13076\\1214727230.py:4: DeprecatedFeatureWarning: content is deprecated, use rawContent instead\n",
      "  print (sncraper_reply.get_items(tweet.content))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_items() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fhb181029\\Documents\\FH\\S9\\MasterArbeit\\Prototyp\\scraper01.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fhb181029/Documents/FH/S9/MasterArbeit/Prototyp/scraper01.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mode \u001b[39m=\u001b[39m sntwitter\u001b[39m.\u001b[39mTwitterTweetScraperMode\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fhb181029/Documents/FH/S9/MasterArbeit/Prototyp/scraper01.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sncraper_reply \u001b[39m=\u001b[39m sntwitter\u001b[39m.\u001b[39mTwitterTweetScraper(tweetId\u001b[39m=\u001b[39m\u001b[39m1647894575510372352\u001b[39m, mode\u001b[39m=\u001b[39mmode\u001b[39m.\u001b[39mSCROLL)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fhb181029/Documents/FH/S9/MasterArbeit/Prototyp/scraper01.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m (sncraper_reply\u001b[39m.\u001b[39;49mget_items(tweet\u001b[39m.\u001b[39;49mcontent))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fhb181029/Documents/FH/S9/MasterArbeit/Prototyp/scraper01.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m replies \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(scraper\u001b[39m.\u001b[39mget_items())\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fhb181029/Documents/FH/S9/MasterArbeit/Prototyp/scraper01.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m number_of_replies \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(\u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m replies)\n",
      "\u001b[1;31mTypeError\u001b[0m: get_items() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "mode = sntwitter.TwitterTweetScraperMode\n",
    "sncraper_reply = sntwitter.TwitterTweetScraper(tweetId=1647894575510372352, mode=mode.SCROLL)\n",
    "\n",
    "print (sncraper_reply.get_items(tweet.content))\n",
    "\n",
    "replies = list(scraper.get_items())\n",
    "number_of_replies = sum(1 for _ in replies)\n",
    "\n",
    "for tweet in replies:\n",
    "    print(tweet.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec985be6afa1855e856968db4e226e01bf3fea1872c8b8a2a592df482132430b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
